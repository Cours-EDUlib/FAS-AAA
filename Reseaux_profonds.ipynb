{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tutoriel_m6_m7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img align=\"left\" src=\"https://drive.google.com/uc?export=view&id=1orv1XTixxkcGADz18uSwN_5kCtd1yM7q\" alt=\"drawing\" width=\"100%\"/>"
      ],
      "metadata": {
        "id": "Hj5VeHlOwKku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img align=\"left\" src=\"https://drive.google.com/uc?id=1dUhDyLOrHHP0ghjdb2ZhvyQZ0ZpcmoIm\" alt=\"drawing\" width=\"200\"/> **<font color = 2b2b99 face=\"Times New Roman\" size=7>Les réseaux de neurones profonds</font>**"
      ],
      "metadata": {
        "id": "7zRKeySGwYn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### <font size=6 color='Red' face = \"Times New Roman\"> &nwarr;Tournez cette cellule avant de débuter.</font>\n",
        "#@markdown ### <font size=4 color='Red' face = \"Times New Roman\"> Ceci prend environ 2 minutes.</font>\n",
        "\n",
        "# NE PAS TOUCHER À CETTE CELLULE\n",
        "# Cette cellule installe les bibliothèques nécessaires pour que le calepin fonctionne.\n",
        "# ici on spécifie les versions des bibliothèques\n",
        "!pip install -q numpy==1.21.5 &> /dev/null #cache les erreurs de dépendance de numpy pour des packages qu'on n'utilise pas\n",
        "!pip install -q pandas==1.3.5 &> /dev/null\n",
        "!pip install -q matplotlib==3.2.2 &> /dev/null\n",
        "!pip install -q torch==1.7.0 &> /dev/null\n",
        "!pip install -q torchtext==0.8.0 &> /dev/null\n",
        "!pip install -q torchvision==0.8.0 &> /dev/null\n",
        "!pip install -q tensorboard==2.2.1 &> /dev/null\n",
        "!pip install -q pytorch-lightning==1.1.0 &> /dev/null\n",
        "\n",
        "# # Il faut repartir le kernel\n",
        "import warnings\n",
        "import sys\n",
        "with warnings.catch_warnings():\n",
        "    print(\"Le calepin est prêt à être utilisé.\")\n",
        "    print(\"Si vous voyez un message de 'crash' en bas à gauche, c'est normal. \")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "9z8TwK7EzWm0",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img align=\"center\" src=\"https://drive.google.com/uc?export=view&id=1HjAM7KY8wrX73rl0F_aOnK5Z-vwwsCrX\" alt=\"drawing\" width=\"100\"/> **<font color = \"3832ba\" face=\"Times New Roman\" size=6>Initialisation</font>**"
      ],
      "metadata": {
        "id": "T1_KJaopBleB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5o6PHYXhKEM"
      },
      "outputs": [],
      "source": [
        "# Importer les modules.\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous travaillerons tout d'abord avec le jeu de données classique MNIST qui contient des images 28x28 de chiffres manuscrits. Il est possible de télécharger les ensembles d'entraînement et d'évaluation directement en utilisant PyTorch, mais nous devons les séparer nous-mêmes."
      ],
      "metadata": {
        "id": "g-gPQYumE2ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Télécharger le jeu de données MNIST.\n",
        "dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
        "train_data, valid_data = torch.utils.data.random_split(dataset, [57000, 3000])\n",
        "test_data = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=ToTensor())"
      ],
      "metadata": {
        "id": "8cDSfbFMhQHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On met nos données dans des DataLoaders.\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "B2Ucbfmqlatj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img align=\"center\" src=\"https://drive.google.com/uc?export=view&id=1HjAM7KY8wrX73rl0F_aOnK5Z-vwwsCrX\" alt=\"drawing\" width=\"100\"/> **<font color = \"3832ba\" face=\"Times New Roman\" size=6>Exploration de données MNIST</font>**"
      ],
      "metadata": {
        "id": "A7z72S3fA4Bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# On examine la forme des données des images.\n",
        "for data in train_loader:\n",
        "    print(type(data), len(data))\n",
        "    X, y = data\n",
        "    # On veut connaître la forme des tensors X et y\n",
        "    # https://pytorch.org/docs/stable/generated/torch.Tensor.size.html\n",
        "    print(...) # Écrire ici\n",
        "    print(...)\n",
        "    break"
      ],
      "metadata": {
        "id": "ryA5r4FnDKje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ainsi, chaque élément `data` du `train_loader` est une liste avec deux (2) éléments, nommés `X` et `y`. `X` est une matrice de 20 images, une (1) « chaîne » de couleur, et 28x28 pixels. `y` indique tout simplement le chiffre correspondant à chacune des 20 images."
      ],
      "metadata": {
        "id": "_93kPXvcDyJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# On visualise quelques chiffres manuscrits.\n",
        "for data in train_loader:\n",
        "    X, y = data\n",
        "    images = X\n",
        "    for i in range(3):\n",
        "        print(y[i])\n",
        "        plt.imshow(images[i].reshape(28,28))\n",
        "        plt.show()\n",
        "    break"
      ],
      "metadata": {
        "id": "NIHSrHmCB1h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img align=\"center\" src=\"https://drive.google.com/uc?export=view&id=1HjAM7KY8wrX73rl0F_aOnK5Z-vwwsCrX\" alt=\"drawing\" width=\"100\"/> **<font color = \"3832ba\" face=\"Times New Roman\" size=6>Définition de modèles initiaux et d'entraînement</font>**"
      ],
      "metadata": {
        "id": "uCk_9aP5A-Ve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour commencer, nous allons utiliser le modèle le plus simple : un réseau de neurone (classique) avec une seule couche connectée. Le modèle prend comme hyperparamètre la taille de la couche cachée."
      ],
      "metadata": {
        "id": "wKdhX7YgTikd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avec la librairie PyTorch, on définit notre modèle sous forme de classe Python (qui hérite de la classe `nn.Module`). On ajoute des couches dans la méthode `__init__()` en utilisant les fonctions fournies par PyTorch telle que `nn.Linear` (pour une couche entièrement connectée) et, enfin, dans la méthode `forward()`, on fait passer nos données à travers toutes les couches."
      ],
      "metadata": {
        "id": "rzRRa0HMFEme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleLayerNN(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        # Ce modèle possède une seule couche caché\n",
        "        # Cette couche possède hidden_size neurones\n",
        "        # On a une entrée de taille 28*28 (taille de l'image)\n",
        "        # On a une sortie de taille 10 (10 chiffres possibles à prédire)\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
        "        self.linear_in = nn.Linear(..., ...) # Écrire ici\n",
        "        self.linear_out = nn.Linear(..., ...)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear_in(x)\n",
        "        x = self.linear_out(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "-LLytdlwVxym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour l'entraînement du modèle, il faut instancier le modèle lui-même, un critère d'optimisation (fonction de perte) et un algorithme d'optimisation (tel que la descente de gradient stochastique, soit SGD)."
      ],
      "metadata": {
        "id": "SuXQ8HX7GEAZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avant de commencer, assurez-vous d'avoir mis votre notebook Colab en mode GPU, ce qui accélère énormément l'entraînement.\n",
        "\n",
        "*Edit > Notebook Settings > Hardware Accelerator > Choisir l'option « GPU »*\n"
      ],
      "metadata": {
        "id": "cCD-_tOyeSKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = SingleLayerNN(hidden_size=64)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Pp9hHOTdkD-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il est également possible de définir certains hyperparamètres, comme le nombre d'itérations, à travers l'ensemble des données. Nous désirons aussi sauvegarder la perte sur l'ensemble d'entraînement **et** sur l'ensemble de validation après chaque itération, donc des variables ont été initialisées ici à cet effet."
      ],
      "metadata": {
        "id": "XHP4HCseGodB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []"
      ],
      "metadata": {
        "id": "1BplrgCXGljV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans chaque *epoch* (itération à travers l'ensemble des données), on fait passer au modèle un lot (*batch*) de données à la fois jusqu'à ce que toutes les données aient été vues.\n",
        "\n",
        "Le processus d'entraînement se passe ainsi :\n",
        "\n",
        "\n",
        "*   On donne un lot de données au modèle.\n",
        "*   La prédiction du modèle est comparée aux vraies valeurs pour produire une valeur de perte (qui est sommée dans une autre variable).\n",
        "*   On rétropropage les gradients par rapport à la perte et on les met à jour avec l'algorithme d'optimisation.\n",
        "\n",
        "Enfin, après chaque *epoch*, on va aussi calculer cette perte, mais sur l'ensemble de validation, ce qui nous permet d'évaluer la capacité de généralisation du modèle.\n"
      ],
      "metadata": {
        "id": "Onbj5gsKHUUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(cnn=True):\n",
        "    for epoch in range(N_EPOCHS):\n",
        "        current_loss = 0.0\n",
        "        for data in train_loader:\n",
        "            X, y = data\n",
        "            # Mettre les données sur GPU.\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # Si le réseau n'est pas convolutionnel, on aplatit les 784 pixels\n",
        "            # dans un image en une dimension.\n",
        "            if not cnn:\n",
        "                X = X.reshape(X.shape[0], -1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X)\n",
        "            loss = criterion(output, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            current_loss += loss.item()\n",
        "        current_loss /= len(train_loader)\n",
        "        train_losses.append(current_loss)\n",
        "\n",
        "        # On imprime les pertes après chaque epoch et on sauvegarde aussi ces valeurs.\n",
        "        print(f\"Epoch {epoch}:\")\n",
        "        print(f\"Training loss: {current_loss}\")\n",
        "        with torch.no_grad():\n",
        "            valid_loss = 0.0\n",
        "            for data in valid_loader:\n",
        "                X, y = data\n",
        "                X = X.to(device)\n",
        "                y = y.to(device)\n",
        "\n",
        "                if not cnn:\n",
        "                    X = X.reshape(X.shape[0], -1)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                output = model(X)\n",
        "                loss = criterion(output, y)\n",
        "\n",
        "                valid_loss += loss.item()\n",
        "            valid_loss /= len(valid_loader)\n",
        "        valid_losses.append(valid_loss)\n",
        "        print(f\"Validation loss: {valid_loss}\")\n",
        "\n",
        "train(cnn=False)"
      ],
      "metadata": {
        "id": "qr0Zc3k3HF5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graphique des pertes après chaque epoch.\n",
        "plt.plot(train_losses)\n",
        "plt.plot(valid_losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u17iJTNamGD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On calcule la précision du modèle final en utilisant l'ensemble de test.\n",
        "def test(cnn=True):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct_predictions = 0\n",
        "        for data in test_loader:\n",
        "            X, y = data\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            if not cnn:\n",
        "                X = X.reshape(X.shape[0], -1)\n",
        "\n",
        "            output = model(X)\n",
        "            correct_predictions += (y == torch.max(output, 1)[1]).sum()\n",
        "        correct_predictions = int(correct_predictions) / len(test_data) * 100\n",
        "    model.train()\n",
        "    print(f\"La précision du modèle final est de {correct_predictions}%\")\n",
        "\n",
        "test(cnn=False)"
      ],
      "metadata": {
        "id": "fJJZYHhxmJWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On va maintenant utiliser un modèle qui convient mieux aux données d'images : un réseau de neurones convolutionnel (CNN). La procédure d'entraînement est le même, mais on devrait obtenir de meilleurs résultats avec le même nombre d'époques d'entraînement."
      ],
      "metadata": {
        "id": "aFknDx02XR9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deuxième modèle : CNN simple\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cnn_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 4, kernel_size=2, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=4)\n",
        "        )\n",
        "        self.linear = nn.Linear(4*7*7,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        # On fait passer x par la couche self.linear\n",
        "        # Conseil: regardez comment x a été passée dans self.cnn_layers! (ligne 15)\n",
        "        x = ...\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "Nfm1-DLGYUuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraînement\n",
        "model = SimpleCNN()\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "train()"
      ],
      "metadata": {
        "id": "3_pqXuzhYWq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluation\n",
        "plt.plot(train_losses)\n",
        "plt.plot(valid_losses)\n",
        "plt.show()\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "id": "pU9iuWzkYlAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img align=\"center\" src=\"https://drive.google.com/uc?export=view&id=1HjAM7KY8wrX73rl0F_aOnK5Z-vwwsCrX\" alt=\"drawing\" width=\"100\"/> **<font color = \"3832ba\" face=\"Times New Roman\" size=6>Modèle CNN avec données différentes</font>**"
      ],
      "metadata": {
        "id": "EL03ngPsu20s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant, avec notre modèle CNN, nous avons eu une précision de plus de 90 % sur les données de test après seulement une minute d'entraînement! Mais, il faut admettre que les chiffres MNIST sont des images plutôt simples. Et si on entraînait ce même modèle sur des images plus complexes?"
      ],
      "metadata": {
        "id": "QoWEL1qhRTIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Télécharger le jeu de données CIFAR-10.\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "     ])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "train_data, valid_data = torch.utils.data.random_split(dataset, [45000, 5000])\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "v_dIRXtQW5TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR-10 est un ensemble de 60 000 images colorées de 32x32 pixels avec 10 classes d'objets.\n",
        "![cifar10.png](https://drive.google.com/uc?export=view&id=1IlJpZZbm_i9jKQG-BJOoX5b8TaSmUOOE)\n",
        "\n",
        "Source : https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "metadata": {
        "id": "JKA8nhH91HPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comme avec MNIST, il serait utile de comprendre le format des données."
      ],
      "metadata": {
        "id": "RFseprPX1p0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for data in train_loader:\n",
        "    print(type(data), len(data))\n",
        "    X, y = data\n",
        "    print(X.shape)\n",
        "    print(y.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "Nx8pLuWL12m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons donc maintenant entraîner notre premier modèle (SimpleCNN) avec ces données CIFAR-10. Le code d'entraînement est le même, mais il faut faire quelques modifications au modèle pour prendre en compte la taille des nouvelles données."
      ],
      "metadata": {
        "id": "M4hQv1nf2MN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Même modèle qu'avant, mais on ajuste certains paramètres pour assurer que les\n",
        "# tailles correspondent à CIFAR-10 (3x32x32 au lieu de 1x28x28).\n",
        "model = SimpleCNN()\n",
        "\n",
        "# La couche d'entrée prend « 3 chaînes » de couleurs (RGB) à la place d'une (1) seule (noir et blanc).\n",
        "model.cnn_layers[0] = nn.Conv2d(3, 4, kernel_size=2, stride=1, padding=1)\n",
        "\n",
        "# Chaque image est un peu plus grande (32x32 au lieu de 28x28).\n",
        "# Donc, la taille de sortie des couches CNN est un peu plus grande aussi.\n",
        "model.linear = nn.Linear(256,10)\n",
        "\n",
        "model.to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "train()"
      ],
      "metadata": {
        "id": "UyyOd5RFRh_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluation du modèle final.\n",
        "plt.plot(train_losses)\n",
        "plt.plot(valid_losses)\n",
        "plt.show()\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "id": "RUxpgztfrGWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il est maintenant clair que notre modèle initial avec une seule couche convolutionnelle n'est plus suffisant face à ces nouvelles données! Ceci malgré le fait que cet entraînement a dû prendre notamment plus de temps que les cas précédents."
      ],
      "metadata": {
        "id": "F-lORFUSTDV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img align=\"center\" src=\"https://drive.google.com/uc?export=view&id=1HjAM7KY8wrX73rl0F_aOnK5Z-vwwsCrX\" alt=\"drawing\" width=\"100\"/> **<font color = \"3832ba\" face=\"Times New Roman\" size=6>Modèle préentraîné</font>**"
      ],
      "metadata": {
        "id": "O7sBbyu5u-w2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En pratique, on a souvent recours aux modèles préentraînés : on télécharge les poids d'un modèle (complexe) qui a déjà été entraîné sur nos données (ou souvent sur des données différentes)."
      ],
      "metadata": {
        "id": "Goz8rJLuTV5r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <img align=\"center\" src=\"https://drive.google.com/uc?export=view&id=1HjAM7KY8wrX73rl0F_aOnK5Z-vwwsCrX\" alt=\"drawing\" width=\"100\"/> <font color = \"3832ba\" face=\"Times New Roman\" size=5>Code pour télécharger le modèle préentraîné (pas besoin de lire cette partie)</font>"
      ],
      "metadata": {
        "id": "QllDQigutG6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source : https://github.com/huyvnphan/PyTorch_CIFAR10"
      ],
      "metadata": {
        "id": "PbQZ3n2ys4F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -sLS https://github.com/huyvnphan/PyTorch_CIFAR10/archive/refs/heads/master.zip > master.zip\n",
        "!unzip master.zip\n",
        "!rm master.zip\n",
        "!mv -v PyTorch_CIFAR10-master/* ./\n",
        "!rm -rf PyTorch_CIFAR10-master/"
      ],
      "metadata": {
        "id": "nNuWpUu_v2Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from data import CIFAR10Data\n",
        "CIFAR10Data.download_weights()"
      ],
      "metadata": {
        "id": "Jpb3r0a9xvBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <img align=\"center\" src=\"https://drive.google.com/uc?export=view&id=1HjAM7KY8wrX73rl0F_aOnK5Z-vwwsCrX\" alt=\"drawing\" width=\"100\"/> <font color = \"3832ba\" face=\"Times New Roman\" size=5>Utiliser le modèle préentraîné</font>"
      ],
      "metadata": {
        "id": "A6P6EH7puez3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cifar10_models.vgg import vgg19_bn\n",
        "model = vgg19_bn(pretrained=True)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "l9prtS-Gsz8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les poids de ce modèle ont déjà été téléchargés, donc il n'est pas nécessaire d'entraîner ce modèle. Vous pouvez voir l'architecture du modèle en question, VGG19, en faisant [une recherche sur Google](https://www.google.com/search?q=vgg19&tbm=isch)."
      ],
      "metadata": {
        "id": "vr0Z-MIc4Jdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluation : il n'y a plus de courbe d'entraînement, car on n'a pas entraîné de modèle!\n",
        "test()"
      ],
      "metadata": {
        "id": "tssm6aY5Y2-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce modèle en particulier a été entraîné sur les images CIFAR-10, le même jeu de données que nous avons utilisé. Par contre, il est aussi possible d'utiliser un modèle ayant été préentraîné sur d'autres données différentes, et, ensuite, de l'ajuster pour nos données afin d'obtenir une meilleure performance."
      ],
      "metadata": {
        "id": "pvf0GXNbTuec"
      }
    }
  ]
}